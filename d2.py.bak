def d2_score(word_length, sequences, mode = 'D2', as_distance = False):
    '''modes are 'D2', 'D*2' and 'DS2' '''
    class SeqHolder(namedtuple('SeqHolder', 'adj_len letter_dist word_count')):
        '''adj_len is the adjusted sequence_length,adj_lenght = sequence_length - word_length'''
        def word_prob(self, word):
            product = lambda iterable: reduce(lambda x,y:x*y, iterable)
            return product((self.letter_dist[letter] for letter in word))
        def normalized_frequency(self, word):
            return float(self.word_count[word]) - self.adj_len * self.word_prob(word)
        
        
    
    def dshep_distance(score, counters):
        '''d2s as in song et al pg 347
        ~x[w] = normalized_frequency count of word w in sequence x 
        pyth = pythogarean distance  = (a^2+b^2)^0.5
        ds2 =  0.5 * ( 1 - (DS2 
                            / 
            ((~x[w]^2)/pyth(~x[w],~y[w]) for w in words) *  ((~y[w]^2)/pyth(~x[w],~y[w]) for w in words)
            ))
        
        '''
        product = lambda iterable: reduce(lambda x,y:x*y, iterable)
        pyth = lambda iterable:math.sqrt(reduce(lambda x,y:x + y**2.0, iterable, 0)) #pythogarean distance,
        pyth_count = lambda counters, word: pyth((normalized_frequency(counter[word]) for counter in counters)) 
        #pythogorean distance of normalized counts of given word in given counters
        return 0.5 * (1 - float(score)                                                  \
                /                                                                       \
            product((                                                                   \
                sum(                                                                    \
                    (normalized_frequency(cur_count[word])**2.0                         \
                                    /                                                   \
                    pyth_count(counters, word) for word in possible_words)              \
                    ) ** 0.5                                                            \
                for cur_count in counters)))
                
    def dstar_distance(score, counters):
        
        product = lambda iterable: reduce(lambda x,y:x*y, iterable)
        correction = product((                                                                  \
            sum(                                                                    \
                (normalized_frequency(cur_count[word]) ** 2.0                       \
                    /                                                               \
                (seq_len * word_prob) for word in possible_words)                   \
                ) ** 0.5                                                            \
            for cur_count in counters))
        return 0.5 * (1 - float(score)/correction)
    def setup_holder(seq, word_length):
        get_words = lambda seq, length: [seq[x:x+length] for x in range(len(seq) - length + 1)]
        seq_len = float(len(seq))
        adj_len = seq_len - word_length
        letter_dist = {letter:seq_len/seq.count(letter)}
        word_count = Counter(get_words(seq, word_length))
        return SeqHolder(adj_len, letter_dist, word_count)
    
    zero_limit = lambda x: x if x > 0 else 0
    assert mode in {'D2', 'D*2', 'DS2'}
    alphabet = ''.join(set(''.join(sequences)))
    possible_words =(''.join(word) for word in itertools.product(*(alphabet,)*word_length))
    for sequence in sequences:

        
    word_prob = (1.0/len(alphabet))**length
    seq_len = max([len(seq) - length for seq in sequences])

    normalized_frequency = lambda count: float(count) - (seq_len*word_prob) 
    stat =  {
             'D2' : lambda counters, word: reduce(lambda x,y: x*y[word], counters, 1),#seq1.count(word) * seq2.count(word) ... seq_n.count(word)
             'D*2': lambda counters, word: reduce(lambda x,y:x*normalized_frequency(y[word]),counters, 1.0) / \
                                                (seq_len*word_prob),
             'DS2': lambda counters, word: reduce(lambda x,y:x*normalized_frequency(y[word]),counters, 1.0) / \
                                            math.sqrt(reduce(lambda x,y:x+(normalized_frequency(y[word])**2), counters, 0.0 )),
            } 
            
    counters = [Counter(get_words(seq, length)) for seq in sequences]
    score = sum([stat[mode](counters, word) for word in possible_words])
    if not as_distance or mode == 'D2':
        return score
    if as_distance:
        possible_words =(''.join(word) for word in itertools.product(*(alphabet,)*length)) #previously was exhausted
        return {
            'D*2':dstar_distance,
            'DS2':dshep_distance,
            }[mode](score, counters)
